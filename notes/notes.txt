- Getting out of bounds error from selenium. Unsure what the cause is.
- Need to implement a reward function
- Need to find a way to predict the coordinates in addition to the action class


WORK LOG:

- Implementing location click points
- Improving Visual_RL Design
- Fixing bugs in training
- Finding out that DQN is not suitable for the task, as the action space is hard to discretise. Continous action space is much more appropriate.
- Reading about methods for continous action space (Actor-Critic, PPO, Policy Gradient)
- Going back to the Eskonen et al paper. Finding out that they use A3C, which poses implementation challenges with 7 simultaneous browser windows open.

- Reading more about Actor-Critic and PPO
- Installing and trying out CleanRL library
- Finding out about "Gym/Gymnasium" environments and how to implement a custom env
- Refactoring the repo
- Begin implementing Gym Environment for Browser

- Continue Gym Environment Development
- Try to get CleanRL to work (failed)
- Try to get Stable-Baseline to work (failed)
- Try to get Stable-Baseline-3 to work (failed)
- Try to get RayLib to work: Looks promising. Should continue down that route


- Test for Raylib Gym Env running through fine, just need to configure the conv net input filter

- Debugging and Learning RayLib

- Parameter Tuning, Environment Tuning
- First Successful Training Run